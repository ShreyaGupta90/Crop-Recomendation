# -*- coding: utf-8 -*-
"""notebooke8b3e635e6

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/shreyajii/notebooke8b3e635e6.e6e268b0-cc94-44a7-8aa1-5dd859b43741.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250910/auto/storage/goog4_request%26X-Goog-Date%3D20250910T153306Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1e284f3b09914b71d2eb39cb86f4bb8514479480671d59515dc2d8f69e3f11afbe4f04f28f3e6d274d3db8bc431320317429b8777f85dd92c64780430523472fec0d869cb0a8cf081df0d4c79dbcc269c27b9c2e1d6a631f0c32d619a2277360ff2ae020fab294d7c1df1e25a911f54b887913254d01e8f4ac6d55096c5bb455e119ac27a92b9b9714348d9b0c15ffbd2db69958f7abe388e7fcd051d3aa87a7ba7946b3388b44b72c7e79dbc9fcf874a7cf13c776f0c3e9c200d8d3c126d1ae744316763ece9740adec500c08dce9a47ec365fa8d4ea15099b1777ac25cc0c374ffa91eb331ddf11b922fb7a534d1f39602f2e894bae1253121d7fe4b0a2234
"""

import numpy as np
import pandas as pd

#for data visualization
import matplotlib.pyplot as plt
import seaborn as sns

# for interactivity
from ipywidgets import interact

from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

import warnings

# Ignore all warnings
warnings.filterwarnings("ignore")

data = pd.read_csv('/content/data (1).csv')

# checking the shape of the dataset
print('Shape of the dataset is: ' , data.shape)

# checking the columns Names
print(data.columns)

# checking dataset data of first 10 rows by using head function..
print(data.head(10))

#checking null values to prevent errors
data.isnull().sum()

# checking the crops preset in our dataset and quantity of it..
data['label'].value_counts()

# checking the summary of all crops

print('Average Ratio of Nitrogen in the soil : {0:2f}'.format(data['N'].mean()))
print('Average Ratio of Phosphorous in the soil : {0:2f}'.format(data['P'].mean()))
print('Average Ratio of Potassium in the soil : {0:2f}'.format(data['K'].mean()))
print('Average Temperature in Celsius : {0:2f}'.format(data['temperature'].mean()))
print('Average Relative Humidity in % : {0:2f}'.format(data['humidity'].mean()))
print('Average PH value of the soil: {0:2f}'.format(data['ph'].mean()))
print('Average Rainfall in mm: {0:2f}'.format(data['rainfall'].mean()))

print('Crops which require very high Ratio of Nitrogen Content in soil :', data[data['N']>120]['label'].unique())

print('Crops which require very high Ratio of Phosphorous Content in soil :', data[data['P']>100]['label'].unique())

print('Crops which require very high Ratio of Potassium Content in soil :', data[data['K']>200]['label'].unique())

print('Crops which require very high Ratio of Rainfall Content in soil :', data[data['rainfall']>200]['label'].unique())

print('Crops which require very low Temperature :', data[data['temperature']<10]['label'].unique())

print('Crops which require very high Temperature :', data[data['temperature']>40]['label'].unique())

print('Crops which require very low HUmidity :', data[data['humidity']<20]['label'].unique())

print('Crops which require very low PH :', data[data['ph']<4]['label'].unique())

print('Crops which require very high PH :', data[data['ph']>9]['label'].unique())

# Understanding which crops can on be grown in summer,winter season and rainy season

print('Summer Season Crops')
print(data[(data['temperature']>30) &(data['humidity']>50)]['label'].unique())
print('-------------------------------------------------')
print('Winter Season Crops')
print(data[(data['temperature']<20) &(data['humidity']>30)]['label'].unique())
print('-------------------------------------------------')
print('Rainy Season Crops')
print(data[(data['rainfall']>200) &(data['humidity']>30)]['label'].unique())

from sklearn.cluster import KMeans

#Removing the label column cause there is no need of label in clustering
x = data.drop(['label'],axis=1)

#Selecting all the values of the data
x = x.values

print(x.shape)

# determine the Optimum Number of Cluster withing dataset
plt.rcParams['figure.figsize']=(10,4)

wcss = []
for i  in range(1,11):
    km = KMeans(n_clusters = i, init= 'k-means++', max_iter = 300, n_init = 10, random_state =0)
    km.fit(x)
    wcss.append(km.inertia_)

#lets plot the results
plt.plot(range(1,11), wcss)
plt.title('The Elbow Method', fontsize=20)
plt.xlabel('No of Clusters')
plt.ylabel('wcss')
plt.show()

# implementing the KMeans algorithm to perform Clustering analysis

km=KMeans(n_clusters = 4, init= 'k-means++', max_iter = 300, n_init = 10, random_state =0)
y_means = km.fit_predict(x)

#lets find out the Results
a = data['label']
y_means= pd.DataFrame(y_means)
z= pd.concat([y_means, a], axis =1)
z=z.rename(columns = {0: 'cluster'})

#let check the clusters of each Crops
print('Crops in First cluster : ', z[z['cluster']==0]['label'].unique())
print('Crops in Second cluster : ', z[z['cluster']==1]['label'].unique())
print('Crops in Third cluster : ', z[z['cluster']==2]['label'].unique())
print('Crops in Fourth cluster : ', z[z['cluster']==3]['label'].unique())

y = data['label']
x = data.drop(['label'], axis = 1)

print('Shape of x: ', x.shape)
print('Shape of Y: ', y.shape)

# let create training and testing sets for validation of results

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)

print('The Shape of x Train: ', x_train.shape)
print('The Shape of x Test: ', x_test.shape)
print('The Shape of y Train: ', y_train.shape)
print('The Shape of y Train: ', y_test.shape)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(x_train, y_train)
y_pred= model.predict(x_test)

data.head()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Compute additional metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted') # Use 'weighted' average for multiclass
recall = recall_score(y_test, y_pred, average='weighted') # Use 'weighted' average for multiclass
f1 = f1_score(y_test, y_pred, average='weighted') # Use 'weighted' average for multiclass

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

prediction = model.predict(np.array([[120,
                                     90,
                                     80,
                                     20,
                                     20,
                                     10,
                                     200]]))
print('The Suggested Crop for Given Climatic Condition is: ', prediction)

import pickle

# Save the trained model to a pickle file
filename = 'crop_recommendation_model.pkl'
pickle.dump(model, open(filename, 'wb'))

print(f"Model saved to {filename}")